The Damage metric here is an idea I have played around with some.  It tries to answer the question, "How likely is a
move to damage the current player's chances of winning?"

This is effectively a win rate.  One could theoretically get a decent approximation using KataGo's new human model.
This would generate some interesting statistics given prior knowledge of each player's rating and whether they are aware
of the other player's strength.

Admittedly, I developed this model before upgrading to KataGo 1.15 and discovering this new behavior.  I still think
this approach is valuable, as it does not require assumptions about either player's strength to perform well.  It uses
metrics generated from the game's history, metrics generated by KataGo's strongest search, and win/rate loss behavior
trained across a small corpus of games I have built and run deep KataGo analysis on (meaning a minimum of 16k visits per
move).  This corpus includes games of DDKs, SDKs, amateur dans, professionals, AlphaGo, Leela Zero, and KataGo.

The idea is simple.  At each move of the game, we can know the following:

- the move index (starting at 1, since there is no Damage when there are no moves)
- the current player's prior lead, or how far/behind they were before they played their move
- the current player's posterior lead, or how far/behind they were after they played their move
- KataGo's prior win rate, or how likely KataGo thinks it would be to win before the current player played
- KataGo's posterior win rate, or how likely KataGo thinks it would be to win after the current player played

I trained a linear regression model using these inputs against the per-move data from my corpus.  This model proved to
be much more accurate in predicting which player would win a game than KataGo's win rate.  It was even to identify when
players were starting to throw a substantial lead that KataGo could not recognize.  The table below shows that the model
performs very closely to the actual win rate for the total positions in that range.

| LR Model p(win) Range | Samples | Wins | Losses | Win Rate | Error |
|-----------------------|--------:|-----:|-------:|---------:|------:|
| [0.00, 0.05)          |    6576 |  183 |   6393 |    0.028 | 0.003 |
| [0.05, 0.10)          |    9225 |  663 |   8562 |    0.072 | 0.003 |
| [0.10, 0.15)          |   10989 | 1420 |   9569 |    0.129 | 0.004 |
| [0.15, 0.20)          |    8350 | 1504 |   6846 |    0.180 | 0.005 |
| [0.20, 0.25)          |    6499 | 1588 |   4911 |    0.244 | 0.006 |
| [0.25, 0.30)          |    6321 | 1650 |   4671 |    0.261 | 0.011 |
| [0.30, 0.35)          |    6927 | 2164 |   4763 |    0.312 | 0.013 |
| [0.35, 0.40)          |    8663 | 3120 |   5543 |    0.360 | 0.015 |
| [0.40, 0.45)          |    9478 | 3870 |   5608 |    0.408 | 0.017 |
| [0.45, 0.50)          |   12022 | 5560 |   6462 |    0.462 | 0.013 |
| [0.50, 0.55)          |   10596 | 5787 |   4809 |    0.546 | 0.021 |
| [0.55, 0.60)          |    7350 | 4345 |   3005 |    0.591 | 0.016 |
| [0.60, 0.65)          |    6675 | 4268 |   2407 |    0.639 | 0.036 |
| [0.65, 0.70)          |    6153 | 4159 |   1994 |    0.676 | 0.001 |
| [0.70, 0.75)          |    6532 | 4802 |   1730 |    0.735 | 0.010 |
| [0.75, 0.80)          |    7067 | 5389 |   1678 |    0.763 | 0.012 |
| [0.80, 0.85)          |    9112 | 7421 |   1691 |    0.814 | 0.011 |
| [0.85, 0.90)          |   10832 | 9479 |   1353 |    0.875 | 0.000 |
| [0.90, 0.95)          |    9245 | 8599 |    646 |    0.930 | 0.005 |
| [0.95, 1.00)          |    7242 | 7044 |    198 |    0.973 | 0.002 |

Generating the same statistics using KataGo's Win Rate metric shows how differently my model performs.  KataGo's
predictions are far off from the actual result rates in those bins.  My model also distributes the positions more
evenly, giving us more confidence that its predictions are reasonable.  KataGo so frequently decides that a game is
completely decided without reckoning how humans can make mistakes.

| KataGo Win Rate Range | Samples |  Wins | Losses | Win Rate | Error |
|-----------------------|--------:|------:|-------:|---------:|------:|
| [0.00, 0.05)          |   44623 |  6785 |  37838 |    0.152 | 0.127 |
| [0.05, 0.10)          |    5635 |  1655 |   3980 |    0.294 | 0.219 |
| [0.10, 0.15)          |    4082 |  1444 |   2638 |    0.354 | 0.229 |
| [0.15, 0.20)          |    3201 |  1217 |   1984 |    0.380 | 0.205 |
| [0.20, 0.25)          |    3237 |  1175 |   2062 |    0.363 | 0.138 |
| [0.25, 0.30)          |    3356 |  1221 |   2135 |    0.364 | 0.089 |
| [0.30, 0.35)          |    3851 |  1260 |   2591 |    0.327 | 0.002 |
| [0.35, 0.40)          |    5153 |  1912 |   3241 |    0.371 | 0.004 |
| [0.40, 0.45)          |    5971 |  2386 |   3585 |    0.400 | 0.025 |
| [0.45, 0.50)          |    7792 |  3617 |   4175 |    0.464 | 0.011 |
| [0.50, 0.55)          |    7317 |  4125 |   3192 |    0.564 | 0.011 |
| [0.55, 0.60)          |    5477 |  3410 |   2067 |    0.623 | 0.002 |
| [0.60, 0.65)          |    4609 |  2986 |   1623 |    0.648 | 0.023 |
| [0.65, 0.70)          |    3478 |  2426 |   1052 |    0.698 | 0.023 |
| [0.70, 0.75)          |    3150 |  2104 |   1046 |    0.668 | 0.057 |
| [0.75, 0.80)          |    2983 |  2001 |    982 |    0.671 | 0.104 |
| [0.80, 0.85)          |    3018 |  1973 |   1045 |    0.654 | 0.171 |
| [0.85, 0.90)          |    3770 |  2606 |   1164 |    0.691 | 0.184 |
| [0.90, 0.95)          |    5111 |  3828 |   1283 |    0.749 | 0.176 |
| [0.95, 1.00)          |   40065 | 34909 |   5156 |    0.871 | 0.104 |

I use this model to calculate a Damage score.  I subtract the player's expected win rate after their move from that
of a hypothetical move that does not change improve or hurt their metrics.  I multiply this by 100, correct for a quirk
in the model, and return that number as the Damage score.

This means that the basic assumption is that a move that causes the current player 1 Damage is now 1 percentage point
less likely to win the game.  As the name implies, Big Damage moves hurt.  The distribution of Damage across all moves in my data (both training and test) was as follows:

| Moment    |   Value | Note                                                                                                    |
|-----------|--------:|---------------------------------------------------------------------------------------------------------|
| Mean      |   3.213 |                                                                                                         |
| Std. Dev. |   6.667 |                                                                                                         |
| Minimum   | -56.467 | It is in fact possible for KataGo to be very surprised.  There can be "healing" moves.  These are rare. |
| Maximum   |  98.391 |                                                                                                         |

| Percentile | Damage |
|-----------:|-------:|
|          5 |  0.000 |
|         10 |  0.000 |
|         15 |  0.000 |
|         20 |  0.000 |
|         25 |  0.000 |
|         30 |  0.000 |
|         35 |  0.000 |
|         40 |  0.001 |
|         45 |  0.189 |
|         50 |  0.470 |
|         55 |  0.828 |
|         60 |  1.261 |
|         65 |  1.802 |
|         70 |  2.502 |
|         75 |  3.415 |
|         80 |  4.692 |
|         85 |  6.679 |
|         90 | 10.145 |
|         95 | 16.849 |


This should show that, even including DDK and SDK games, it is normal for most moves to cause little Damage.  This
metric has the behavior of highlighting moves that are worthy of investigation, especially since it can catch moves that
a loss metric (points lost) or a drop metric (win rate lost) would miss on their own.

This metric has been added into GTP Personality so that bots can choose to use this value to filter moves.

The Damage metric was developed in a project I put together months before I thought of this project.  Its structure was
fairly different.  I decided it was acceptable to export a pickled version of the trained model and load the code it
expected from its project instead of trying to rewrite that project to fit my new approach.

As such, it is cleaner and easier to use the `calculate_damage()` function I have put in the `damage` model instead of
trying to use this package.